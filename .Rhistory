myvar <- paste(state.info$population,state.info$population >3000 , sep="")
myvar
new.state.info <- state.info[myvar]
source('E:/R/Subset.R')
source('E:/R/Subset.R')
sample(1:30, 50, replace=F)
sample(1:30, 20, replace=F)
state.info[sample(1:40, 10, replace=F)]
state.info[sample(1:40, 10, replace=F, c(1,4,7))]
state.info[sample(1:40, 10, replace=F),]
state.info[sample(1:40, 10, replace=F), c(1,2)]
source('E:/R/Subset.R')
state.info [state.region == 1, select = c("X", "state.abb", "state.region")]
state.info [state.region == 1, select = c(X, state.abb, state.region)]
subset(state.info, state.region == 1, select = c(X, state.abb, state.region))
source('E:/R/Subset.R')
head(state.info,c=(1,4,7))
head(state.info,4)
head(state.info,4, c=(1,4,6))
tail(state.info, ,1)
tail(state.info, ,2)
source('E:/R/Subset.R')
names(state.info)
state.info[names(state.info) %in% c("area", "frost")]
state.info[c(-1, -4, -7)]
names(state.info) %in% c("area", "frost")
names(state.info) %in% c("area", "fros")
names(state.info) %in% c("area", "frost")
source('E:/R/Subset.R')
source('E:/R/Subset.R')
source('E:/R/Subset.R')
?state.info
mtcars
summary(mtcars)
efficient <- subset(mtcars, mpg >= 23)
efficient
nrow(efficient)
table(efficient)
dim(efficient)
mtcars[qsec < 16.90]
mtcars
mtcars[mtcars$qsec < 16.90]
mtcars[qsec < 16.90]
mtcars[qsec =< 16.90]
mtcars[qsec <= 16.90]
mtcars[mtcars$qsec <= 16.90]
mtcars$qsec
mtcars$qsec <= 16.9
mtcars[mtcars$qsec <= 16.9]
subset(mtcars, qsec <= 16.9)
source('E:/R/Subset.R')
source('E:/R/Subset.R')
source('E:/R/Subset.R')
light.cars <- subset(mtcars, wt< 2)
light.cars <- subset(mtcars, wt< 2)
nrow (light.cars)
lightcars
light.cars <- subset(mtcars, wt< 2)
nrow (light.cars)
light.cars
source('E:/R/Table.R')
mtcars
mtcars$year <-1974
mtcars
mtcars
mtcars <- mtcars[-year]
mtcars <- mtcars[-mtcars$year]
mtcars
mtcars <- mtcars[select= -mtcars$year]
mtcars <- mtcars[c(-12)]
mtcars
mtcars$year <- c(1973,1974)
mtcars <- mtcars[c(-"year")]
mtcars <- subset(mtcars, select =c(-12))
mtcars
source('E:/R/Table.R')
mtcars$wt
cond <- mtcars$wt < 3
cond
mtcars$weight_class <- ifelse(cond, 'light', 'average')
mtcars$weight_class
cond <- mtcars$wt > 3.5
mtcars$weight_class <- ifelse(cond, 'heavy', mtcars$weight_class)
mtcars$weight_class
rm(cond)
rm(efficient)
source('E:/R/Table.R')
source('E:/R/Table.R')
install.packages('knitr', dependencies = T)
library(knitr)
mtcars[mtcars$mpg >= 30 | mtcars$hp < 60, c=(1)]
mtcars[mtcars$mpg >= 30 | mtcars$hp < 60, ,c=(1)]
mtcars[mtcars$mpg >= 30 | mtcars$hp < 60]
mtcars
subset(mtcars, mpg >= 30 | hp <60)
subset(mtcars, mpg >= 30 | hp <60, c(1))
mtcars [ mtcars$mpg >=30]
mtcars [mpg >=30]
mtcars[mpg >=30, ]
state.info [ state.info$state.region ==1, c(1,3,4)]
state.info [ state.info$state.region > 1, c(1,3,4)]
View(mtcars)
mtcars [ mtcars$mpg > 3-]
mtcars [ mtcars$mpg > 30]
mtcars [ mtcars$mpg > 30, c(1,4,5)]
subset(state.info, state.region ==1 | state.region >=3, )
subset(state.info, state.region ==1 | state.region >=3,c(1) )
source('E:/R/Table.R')
install.packages("Hmisc")
?Hmics
?Hmisc
conc <- c(0.2, 0.5, 1, 2, 5 )
abs <- c(0.0104, 0.259, 0.0518, 0.1024, 0.2437)
reg  <- lm( abs ~ conc )
plot( abs ~ conc )
summary ( reg )
> summary ( reg )
conc <- c(0.2, 0.5, 1, 2, 5 )
abs <- c(0.0104, 0.0259, 0.0518, 0.1024, 0.2437)
reg  <- lm( abs ~ conc )
plot( abs ~ conc )
summary ( reg )
abline( reg )
conc <- c(0, 0.2, 0.5, 1, 2, 5 )
abs <- c(0.001, 0.0104, 0.0259, 0.0518, 0.1024, 0.2437)
reg  <- lm( abs ~ conc )
plot( abs ~ conc )
summary ( reg )
abline( reg )
0.997* conc
conc <- c(0.00005, 0.0001, 0.00015, 0.0002, 0.00025)
A <- c(0.2247, 0.4619, 0.69994, 0.9320, 1.1695)
reg <- lm(A ~ conc)
summary (reg)
plot( A ~ conc)
abline (reg)
ep = A/(conc/5)
ep
mean(ep)
predict(0.9252,reg)
predict (reg, 0.9252)
0.2247/(0.5e-3/5)
conc <- c( 0.5e-3, 1e-3, 1.5e-3, 2e-3, 2.5e-3)
A <- c(0.2247, 0.4619, 0.69994, 0.9320, 1.1695)
reg <- lm(A ~ conc)
summary (reg)
plot( A ~ conc)
abline (reg)
ep = A/(conc/5)
ep
mean(ep)
0.9252/2311.727
0.9252/2311.727*10
(0.9252+0.0103)/471.94
((0.9252+0.0103)/471.94)/5*10
(0.9252+0.0103)/471.94)
(0.9252+0.0103)/471.94
conc <- c( 0.5e-3, 1e-3, 1.5e-3, 2e-3, 2.5e-3)
A <- c(0.2247, 0.4619, 0.69994, 0.9320, 1.1695)
reg <- lm(A ~ conc)
summary (reg)
plot( A ~ conc)
abline (reg)
ep = A/(conc/5)
ep
mean(ep)
((0.9252+0.0103)/471.94)/5*10
par(mfrow = c(2,2))
x <- runif(N, -4, 4)
N <- 200
x <- runif(N, -4, 4)
x
x
install.packages(c("car", "psych"))
FB.Data...Copy <- read.table("C:/Users/KIM LONG/Desktop/SGH/FB Data - Copy.txt", header=TRUE, quote="\"")
View(FB.Data...Copy)
FB.Data...Copy <- read.csv("C:/Users/KIM LONG/Desktop/SGH/FB Data - Copy.csv")
View(FB.Data...Copy)
Loai <- FB.Data$Loai
Loai
Data <- read.csv("C:/Users/KIM LONG/Desktop/SGH/Data.csv")
View(Data)
Data
Type <- as.factor(Data$Loai)
Type
Time.Frame <- as.factor(Data$Time.Frame)
Time.Frame
Total <- Data$Total
Total
reg <- lm(Total ~ Type + Time.Frame)
summary(reg)
Data <- read.csv("C:/Users/KIM LONG/Desktop/SGH/Data.csv")
View(Data)
Type <- as.factor(Data$Loai)
Total <- Data$Total
Time.Frame <- as.factor(Data$Time.Frame)
reg <- lm(Total ~ Type + Time.Frame)
summary(reg)
Type <- as.factor(Data$Loai)
Total <- Data$Total
Time.Frame <- as.factor(Data$Time.Frame)
reg <- lm(Total ~ Type)
Data <- read.csv("C:/Users/KIM LONG/Desktop/SGH/Data.csv")
View(Data)
Type <- as.factor(Data$Loai)
Total <- Data$Total
Time.Frame <- as.factor(Data$Time.Frame)
reg <- lm(Total ~ Type)
summary(reg)
anova(reg)
install.packages(c("evaluate", "formatR", "Formula", "highr", "Hmisc", "knitr", "lattice", "lme4", "manipulate", "markdown", "mime", "mnormt", "plyr", "psych", "quantreg", "Rcpp", "RcppEigen", "RCurl", "rgl", "rmarkdown", "scales", "SparseM", "stringr", "XML"))
source("http://bioconductor.org/biocLite.R")
biocLite()
setwd("E:/R")
library(KernSmooth)
qnorm(0.1,21,5)
qnorm(0.1,21,5)
qnorm(0.1,21,5)
qnorm(0.1,21,5)
qnorm(0.1,21,5)
1-(10,10,0.93)
1-dbinom(10,10,0.93)
1-0.93^10
1-pnorm(34,24,4)
dbinom(50,160,0.28)
1-pbinom(49.5,160,0.28)
sum(dbinom(50:160,160,0.28))
download.file(url = "http://bit.ly/dasi_project_template", destfile = "dasi_project_template.Rmd")
?runif
?transform
n <- 1000
df1 <- data.frame(x1=runif(n,0,100),
x2=runif(n,0,100))
df1 <- transform(df1,
y=1+ifelse(100 - x1 - x2 + rnorm(n,sd=10) < 0, 0,
ifelse(100 - 2*x2 + rnorm(n,sd=10) < 0, 1, 2)),
set="Original")
plot(df1)
setwd("C:/Users/KIM LONG/Desktop/Strategy")
Let's load our dataset
dataold=read.table('DATA_3.02_HR2.csv', header = T,sep=',') # The function read.table enables us to read flat files such as .csv files
datanew=read.table('DATA_4.02_HR3.csv', header = T,sep=',') # Th
logreg = glm(left ~ ., family=binomial(logit), data=dataold) # Estimate the drivers of attrition
probaToLeave=predict(logreg,newdata=datanew,type="response")
rm(list=ls(all=TRUE))
# Let's load our dataset
dataold=read.table('DATA_3.02_HR2.csv', header = T,sep=',') # The function read.table enables us to read flat files such as .csv files
datanew=read.table('DATA_4.02_HR3.csv', header = T,sep=',') # The new dataset on which we want to make the prediction
str(datanew) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(datanew) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
logreg = glm(left ~ ., family=binomial(logit), data=dataold) # Estimate the drivers of attrition
probaToLeave=predict(logreg,newdata=datanew,type="response") # Make predictions on the out-of-sample data
resid(logreg)
summary(logreg)
table(dataold$left)
x <- data.frame(table(dataold$left))
x
predattrition
predattrition = data.frame(probaToLeave) # Structure the prediction output in a table
View(predattrition) # View the predattrition dataframe
predattrition$performance=datanew$LPE
View(predattrition
)
plot(predattrition$probaToLeave,predattrition$performance)
predattrition$priority=predattrition$performance*predattrition$probaToLeave
View(predattrition)
orderpredattrition=predattrition[order(predattrition$priority,decreasing = TRUE),]
View(orderpredattrition)
plot(predattrition$probaToLeave,predattrition$performance)
abline(v = 0.3, col ="red")
abline(h = 0.54, col = "red")
plot(predattrition$probaToLeave,predattrition$performance, pch = 20)
abline(v = 0.3, col ="red")
abline(h = 0.54, col = "red")
text(0.15, 0.7, "As usual")
text(0.15, 0.7, "As usual", col ="red")
text(0.35, 0.45, " Up or out", col = "red")
text(0.6, 0.8, "Must retain", cl = "red" )
text(0.6, 0.8, "Must retain", col = "red" )
plot(predattrition$probaToLeave,predattrition$performance, pch = 20, fb ="yellow", bg ="white")
plot(predattrition$probaToLeave,predattrition$performance, pch = 20, col = "yellow")
abline(v = 0.3, col ="red")
abline(h = 0.54, col = "red")
text(0.15, 0.7, "As usual", col ="red") #good performance,low left
text(0.35, 0.45, " Up or out", col = "red") #low performance
plot(predattrition$probaToLeave,predattrition$performance, pch = 20, col = "blue")
plot(predattrition$probaToLeave,predattrition$performance, pch = 20, col = "blue")
abline(v = 0.3, col ="red")
abline(h = 0.54, col = "red")
text(0.15, 0.7, "As usual", col ="red") #good performance,low left
text(0.35, 0.45, " Up or out", col = "red") #low performance
text(0.6, 0.8, "Must retain", col = "red" ) #high perf, high left
# to clean up the memory of your current R session run the following line
rm(list=ls(all=TRUE))
# Let's load the data
data=read.table('DATA_4.03_MNT.csv',sep=',',header=TRUE)
str(data)
summary(data)
rm(list=ls(all=TRUE))
data=read.table('DATA_4.03_MNT.csv',sep=',',header=TRUE)
str(data)
summary(data)
linregmodel = lm(lifetime~.-broken,data=data) #exclude "broken"
summary(linregmodel)
library(survival)
install.packages(c("evaluate", "formatR", "highr", "Hmisc", "manipulate", "R.matlab", "RcppEigen"))
install.packages("survival") # Install the survival package to your computer
library(survival)
install.packages("survival") # Install the survival package to your computer
library(survival)
install.packages("survival")
library(survival)
?survreg
dependantvars = Surv(data$lifetime, data$broken)
dependantvars
dependantvars = Surv( data$broken, data$lifetime)
dependantvars = Surv(data$lifetime, data$broken)
dependantvars
dependantvars = Surv(data$lifetime, data$broken)
survreg = survreg(dependantvars~pressureInd+moistureInd+temperatureInd+team+provider, dist="gaussian",data=data) # Create your survival regression model
summary(survreg)
Ebreak=predict(survreg, newdata=data, type="quantile", p=.5)
Ebreak
?predict
Ebreak=predict(survreg, newdata=data, type="quantile", p=.5)
Forecast=data.frame(Ebreak)
View(Forecast)
Ebreak=predict(survreg, newdata=data, type="quantile", p=.05)
Forecast=data.frame(Ebreak)
View(Forecast)
Ebreak=predict(survreg, newdata=data, type="quantile", p=.05)
Forecast1=data.frame(Ebreak)
View(Forecast1)
fitted.values(survreg)
Ebreak=predict(survreg, newdata=data, type="quantile")
Forecast1=data.frame(Ebreak)
View(Forecast1)
Ebreak=predict(survreg, newdata=data, type="response")
Forecast2=data.frame(Ebreak)
View(Forecast2)
Ebreak=predict(survreg, newdata=data, type="quantile", p = 0.95)
Forecast3=data.frame(Ebreak)
View(Forecast3)
Ebreak=predict(survreg, newdata=data, type="quantile", p = 0.75)
Forecast4=data.frame(Ebreak)
View(Forecast4)
Ebreak=predict(survreg, newdata=data, type="quantile", p = 0.9)
Forecast4=data.frame(Ebreak)
View(Forecast4)
Ebreak=predict(survreg, newdata=data, type="quantile")
Forecast1=data.frame(Ebreak)
View(Forecast1)
Ebreak=predict(survreg, newdata=data, type="quantile", p=c(0.1, 0.5, 0.9))
## type = "quantile" -> return value at the p quantile. if left out p, return at 0.1 and 0.9
Forecast1=data.frame(Ebreak)
View(Forecast1)
fitted(survreg)
## estimate the median lifetime as the expected moment of "death"
Ebreak=predict(survreg, newdata=data, type="quantile", p= 0.5)
## type = "quantile" -> return value at the p quantile. if not indicate p, return at 0.1 and 0.9
## tyep = "response" -> return the mean value
Forecast=data.frame(Ebreak)
View(Forecast)
Forecast$lifetime=data$lifetime  # Add a column in the Forecast dataframe indicating the lifetime of the piece
Forecast$broken=data$broken # Add a column in the Forecast dataframe indicating whether or not the piece is broken
Forecast$RemainingLT=Forecast$Ebreak-data$lifetime # Computed Expected Remaining Lifetime
View(Forecast) # View the complete Forecast dataframe
Forecast=Forecast[order(Forecast$RemainingLT),] # Order the elements by Expected Remaining Lifetime
ActionsPriority=Forecast[Forecast$broken==0,] # And keep only those who are not broken yet
View(ActionsPriority) # View the output and take actions!
rm(list=ls())
# Let's load our dataset and call it data
data=read.table('DATA_4.04_CHOC.csv',sep=',',header=TRUE) # The fu
str(data)
summary(data$sales)
pairs(data)
year
summary(data$year)
plot(data$time,data$sales,
main="Chocolate sales over time",
xlab="Time (in month)",
ylab="Monthly sales",
ylim=c(0,max(data$sales*1.2)),
type='l') #lined
View(data)
summary(regres)
regres=lm(sales~month,data=data) # Build a linear regression model
summary(regres)
plot(data$month,data$sales,
main="Chocolate sales by month",
xlab="Month",ylab="Monthly sales",
ylim=c(0,max(data$sales*1.2)))
lines(data$time,regres$fitted.values,type='l',col='blue',lty=2)
legend("topleft",c("Actual sales","Sales by the model"),lty=c(1,2),col=c('black','blue'))
legend("topleft",c("Actual sales","Sales by the model"),lty=c(2,1),col=c('black','blue'))
legend("topleft",c("Actual sales","Sales by the model"),lty=c(1,2),col=c('black','blue'))
rm(list=ls(all=TRUE))
# Let's load our dataset
dataold=read.table('DATA_3.02_HR2.csv', header = T,sep=',') # The function read.table enables us to read flat files such as .csv files
datanew=read.table('DATA_4.02_HR3.csv', header = T,sep=',') # The new dataset on which we want to make the prediction
logreg = glm(left ~ ., family=binomial(logit), data=dataold)
predattrition = data.frame(probaToLeave)
logreg = glm(left ~ ., family=binomial(logit), data=dataold) # Estimate the drivers of attrition
probaToLeave=predict(logreg,newdata=datanew,type="response") # Make predictions on the out-of-sample data
predattrition = data.frame(probaToLeave) # Structure the prediction output in a table
View(predattrition) # View the predattrition dataframe
probaToLeave=predict(logreg,newdata=dataold,type="response") # Make predictions on the out-of-sample data
predattrition1 = data.frame(probaToLeave) # Structure the prediction output in a table
View(predattrition1) # View the predattrition dataframe
predattrition$performance=datanew$LPE # Add a column to the predattrition dataframe containing the performance
View(predattrition)
merge.data.frame(dataold, datanew)
data <- merge.data.frame(dataold, datanew)
str(data)
data <- merge(dataold, datanew)
str(data)
head(dataold)
head(datanew)
rm(list=ls(all=TRUE))
# Let's load our dataset
dataold=read.table('DATA_3.02_HR2.csv', header = T,sep=',') # The function read.table enables us to read flat files such as .csv files
datanew=read.table('DATA_4.02_HR3.csv', header = T,sep=',')
dataold.90 <- dataold[dataold$LPE > 0.9]
dataold
head(dataold)
dataold.90 <- dataold[dataold$LPE > 0.9]
dataold.90 <- dataold[LPE > 0.9]
dataold.90 <- dataold[dataold$LPE > 0.9]
dataold.90 <- dataold[dataold$LPE == 0.9]
dataold.90 <- dataold[, dataold$LPE > 0.9]
dataold.90 <- dataold[, dataold$LPE > 0.9, ]
dataold.90 <- dataold[ dataold$LPE > 0.9, ]
View(dataold.90)
logreg = glm(left ~ ., family=binomial(logit), data=dataold) # Estimate the drivers of attrition
probaToLeave=predict(logreg,newdata=dataold,type="response") # Make predictions on the out-of-sample data
predattrition = data.frame(probaToLeave) # Structure the prediction output in a table
View(predattrition) # View the predattrition dataframe
predattrition$performance=datanew$LPE# Add a column to the predattrition dataframe containing the performance
predatrition.90 <- predattrition[predattrition$LPE >= 0.9,]
View(predattrition) # View the predattrition dataframe
logreg = glm(left ~ ., family=binomial(logit), data=dataold) # Estimate the drivers of attrition
probaToLeave=predict(logreg,newdata=dataold,type="response") # Make predictions on the out-of-sample data
predattrition = data.frame(probaToLeave) # Structure the prediction output in a table
View(predattrition) # View the predattrition dataframe
predattrition$performance=datanew$LPE# Add a column to the predattrition dataframe containing the performance
predatrition.90 <- predattrition[predattrition$performance >= 0.9,]
View(predattrition) # View the predattrition dataframe
View(predattrition.90)
predatrition.90 <- predattrition[predattrition$performance >= 0.9,]
View(predattrition.90)
predatrition.90
View(predatrition.90)
logreg = glm(left ~ ., family=binomial(logit), data=dataold) # Estimate the drivers of attrition
probaToLeave=predict(logreg,newdata=dataold,type="response") # Make predictions on the out-of-sample data
predattrition = data.frame(probaToLeave) # Structure the prediction output in a table
View(predattrition) # View the predattrition dataframe
predattrition$performance=dataold$LPE# Add a column to the predattrition dataframe containing the performance
predatrition.90 <- predattrition[predattrition$performance >= 0.9,]
View(predatrition.90) # View the predattrition dataframe
predatrition.90 <- predattrition[predattrition$performance >= 0.9,]
View(predatrition.90) # View the predattrition dataframe
logreg = glm(left ~ ., family=binomial(logit), data=dataold) # Estimate the drivers of attrition
probaToLeave=predict(logreg,newdata=datanew,type="response") # Make predictions on the out-of-sample data
predattrition = data.frame(probaToLeave) # Structure the prediction output in a table
predattrition$performance=datanew$LPE# Add a column to the predattrition dataframe containing the performance
predatrition.90 <- predattrition[predattrition$performance >= 0.9,]
View(predatrition.90) # View the predattrition dataframe
# Set your directory to the folder where you have downloaded the Predictive Maintenance dataset
# to clean up the memory of your current R session run the following line
rm(list=ls(all=TRUE))
# Let's load the data
data=read.table('DATA_4.03_MNT.csv',sep=',',header=TRUE)
str(data) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(data) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
linregmodel = lm(lifetime~.-broken,data=data)  # Build a linear regression model
summary(linregmodel) # The summary() function shows the output of your model
install.packages("survival") # Install the survival package to your computer
library(survival) # Load the survival package
dependantvars = Surv(data$lifetime, data$broken) # choose the dependant variables to be used in the survival regression model with the Surv() function
survreg = survreg(dependantvars~pressureInd+moistureInd+temperatureInd+team+provider, dist="gaussian",data=data) # Create your survival regression model
summary(survreg)  # The summary() function shows the output of your model
Ebreak=predict(survreg, newdata=data, type="quantile", p=.5) # Make predictions based on the model. Here we estimate the median lifetime as the expected moment of "death"
Forecast=data.frame(Ebreak) # Create a dataframe to store the ouput of Ebreak
Forecast$lifetime=data$lifetime  # Add a column in the Forecast dataframe indicating the lifetime of the piece
Forecast$broken=data$broken # Add a column in the Forecast dataframe indicating whether or not the piece is broken
Forecast$RemainingLT=Forecast$Ebreak-data$lifetime # Computed Expected Remaining Lifetime
View(Forecast) # View the complete Forecast dataframe
Forecast=Forecast[order(Forecast$RemainingLT),] #order by Increasing value
ActionsPriority=Forecast[Forecast$broken==0,] # And keep only those who are not broken yet
View(ActionsPriority) # View the output and take actions!
install.packages("survival")
summary(survreg)
survreg = survreg(dependantvars~pressureInd+moistureInd+temperatureInd, dist="gaussian",data=data) # Create your survival regression model
summary(survreg)  # The summary() function shows the output of your model
rm(list=ls(all=TRUE))
# Let's load our dataset
dataold=read.table('DATA_3.02_HR2.csv', header = T,sep=',') # The function read.table enables us to read flat files such as .csv files
datanew=read.table('DATA_4.02_HR3.csv', header = T,sep=',') # The new dataset on which we want to make the prediction
str(datanew) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(datanew) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
logreg = glm(left ~ ., family=binomial(logit), data=dataold) # Estimate the drivers of attrition
probaToLeave=predict(logreg,newdata=datanew,type="response") # Make predictions on the out-of-sample data
predattrition = data.frame(probaToLeave) # Structure the prediction output in a table
predattrition$performance=datanew$LPE# Add a column to the predattrition dataframe containing the performance
predatrition.90 <- predattrition[predattrition$performance >0.9,]
View(predatrition.90) # View the predattrition dataframe
logreg = glm(left ~ ., family=binomial(logit), data=dataold) # Estimate the drivers of attrition
probaToLeave=predict(logreg,newdata=dataold,type="response") # Make predictions on the out-of-sample data
predattrition = data.frame(probaToLeave) # Structure the prediction output in a table
predattrition$performance=dataold$LPE# Add a column to the predattrition dataframe containing the performance
predatrition.90 <- predattrition[predattrition$performance >0.9,]
View(predatrition.90) # View the predattrition dataframe
